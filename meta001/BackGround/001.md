메타 러닝(Meta-learning)?

+ 메타 러닝은 가장 일반적으로 '학습하는 법을 학습하기(learning to learn)'로 이해할 수 있습니다.
+ 이는 다수의 학습 에피소드에 걸쳐 학습 알고리즘을 개선하는 과정을 의미합니다.
+ 이와 대조적으로, 기존의 머신 러닝(ML)은 다수의 데이터 인스턴스를 통해 모델의 예측 성능을 개선합니다.

두 단계로 나눠보겠습니다.

**베이스 러닝(base learning)** 단계   

+ **내부(또는 하위/베이스) 학습 알고리즘**이 데이터셋과 목표(objective)에 의해 정의된 이미지 분류와 같은 태스크를 해결합니다.

**메타 러닝** 단계   

+ **외부(또는 상위/메타) 알고리즘**이 내부 학습 알고리즘을 갱신, 내부 알고리즘이 학습한 모델이 외부 목표를 개선할 수 있도록 합니다.
+ 예를 들어, 이러한 외부 목표는 내부 알고리즘의 일반화 성능이나 학습 속도가 될 수 있습니다.

베이스 태스크의 학습 에피소드는 하나의 튜플로 구성할 수 있는데요.

+ (베이스 알고리즘, 학습된 모델, 성능)로 주어질 수 있습니다.
+ 외부 알고리즘이 베이스 학습 알고리즘을 학습하는 데 필요한 인스턴스를 제공하는 것으로 볼 수 있습니다.

보통의 경우에, 

+ 메타 러닝은 특정 태스크 패밀리(task family)에서 추출된 학습 에피소드들을 바탕으로 수행되며, 이를 통해 해당 패밀리에서 추출된 새로운 태스크들에 대해 우수한 성능을 보이는 베이스 학습 알고리즘을 도출합니다. 
+ 그러나 제한적인 경우에는 모든 훈련 에피소드가 단일 태스크에서 추출될 수도 있습니다.

### 일반적인 경우: 태스크 패밀리(Task Family) 기반 학습

+ 의미: 메타 러닝의 가장 대표적인 형태입니다. 비슷한 종류의 문제들(=태스크 패밀리)을 여러 개 풀면서 공통된 '요령'을 익히는 것입니다.
+ 예시 (이미지 분류):
  + 태스크 패밀리: "동물 사진 분류하기"
  + 학습 에피소드 1: 개 vs 고양이 분류 학습
  + 학습 에피소드 2: 사자 vs 호랑이 분류 학습
  + 결과 (새로운 태스크): 이제 모델은 "동물을 분류하는 법"에 대한 요령(메타 지식)이 생겼으므로, 처음 보는 '코끼리 vs 기린' 사진을 보여줘도 아주 빠르게 학습해냅니다.
+ 핵심: 이미 경험한 태스크들을 통해 새로운 태스크를 잘 풀게 만드는 것이 목표입니다.

### 제한적인 경우: 단일 태스크(Single Task) 기반 학습

+ 의미: 메타 러닝의 원리를 오직 하나의 큰 문제를 잘 푸는 데 사용하는 경우입니다. 겉보기에는 일반적인 머신러닝과 비슷해 보이지만, **'스스로 학습 방식을 조절한다'**는 메타 러닝의 메커니즘을 사용한다는 점이 다릅니다.
+ 작동 방식: 하나의 큰 태스크를 여러 개의 작은 구간(에피소드)으로 쪼개서, 앞부분을 학습하며 얻은 '학습 노하우'를 뒷부분 학습에 써먹는 식입니다.

<details>
<summary>아주 약간의 아이디어</summary>

저희 논문 "Spatiotemporal Attention with Conditional Feature Modulation for Satellite-Based Solar Irradiance Prediction"은 

+ 시계열 데이터(위성 영상)를 다루고 있으며,
+ 계절적 변화와 구름의 역동성을 포착하는 것이 핵심 과제입니다.

여기서 **'단일 태스크(Single Task) 기반 메타 러닝'**관점의 접급을 생각해봤습니다. 

+ **한국 한반도 영역의 태양광 예측이라는 하나의 거대한 태스크**를 수행하면서,
+ 시계열 데이터를 구간별로 나누어 각 구간을 하나의 '에피소드'로 간주하고,
+ 이를 통해 모델이 변화하는 기상 상황(계절, 구름 패턴 등)에 스스로 적응하도록 만드는 전략을 의미합니다.

AC U-Net에 적용할 수 있는 5가지 아이디어와 수식은 다음과 같이 좀 제시해드립니다.

---

### 1. Online Meta-Learning (Test-Time Training)
**개념:** 논문의 AC U-Net은 오프라인에서 학습된 고정된 가중치 $\theta$를 사용합니다. 하지만 기상 상황은 실시간으로 변합니다. 과거의 데이터를 'Support Set'으로, 현재 예측해야 할 시점을 'Query Set'으로 정의하여, **추론 단계에서도 모델이 최근 몇 시간의 데이터에 맞춰 파라미터를 미세조정(Fine-tuning)하도록 메타 러닝**합니다. 즉, 초기 가중치 $\theta$를 "어떤 기상 상황에도 빠르게 적응할 수 있는 상태"로 학습합니다.

*   **수식 및 노테이션:**
    *   모델 파라미터: $\theta$
    *   시점 $t$에서의 입력(과거 프레임)과 정답: $(X_t, Y_t)$
    *   **Support Set (최근 과거):** $\mathcal{D}^{tr}_t = \{(X_{t-k}, Y_{t-k})\}_{k=1}^{K}$ (예: 직전 1~2시간 데이터)
    *   **Query Set (현재 예측):** $\mathcal{D}^{val}_t = \{(X_t, Y_t)\}$ (실제 추론 시에는 $Y_t$가 없으므로 메타 학습 시에만 검증용으로 사용)
    *   **Inner Loop (적응):** 현재 시점 $t$에 맞춰 파라미터 $\theta$를 임시 파라미터 $\theta'_t$로 갱신 (Gradient Descent 1~수 회)
        $$ \theta'_t = \theta - \alpha \nabla_\theta \mathcal{L}_{task}(\mathcal{D}^{tr}_t; \theta) $$
    *   **Outer Loop (메타 목표):** 적응된 파라미터 $\theta'_t$가 실제 미래($Y_t$)를 잘 맞추도록 초기 파라미터 $\theta$를 업데이트
        $$ \theta^* = \arg\min_{\theta} \sum_{t} \mathcal{L}_{meta}(\mathcal{D}^{val}_t; \theta'_t) $$
*   **기대 효과:** 갑작스러운 기상 변화(예: 태풍 접근, 급격한 구름 생성) 시, 고정된 모델보다 훨씬 정확한 단기 예측(Nowcasting)이 가능합니다.

### 2. Meta-Learning Loss Weights (Dynamic Loss Balancing)
**개념:** 논문에서는 손실 함수로 `Total Loss`를 정의할 때 $\alpha=0.025$로 고정하여 사용했습니다 ($\mathcal{L}_{total} = \alpha \cdot \mathcal{L}_{MS-SSIM} + (1-\alpha) \cdot \mathcal{L}_{MAE}$). 하지만 맑은 날에는 픽셀 에러(MAE)가 중요하고, 흐린 날에는 구조적 유사도(SSIM)가 더 중요할 수 있습니다. 메타 러닝을 통해 **입력 이미지의 특성에 따라 $\alpha$ 값을 동적으로 조절하는 네트워크**를 학습합니다.

*   **수식 및 노테이션:**
    *   베이스 모델 파라미터: $\theta$
    *   메타 네트워크(Loss Weight Generator) 파라미터: $\omega$
    *   메타 네트워크는 입력 $X_t$의 특징(Feature)을 받아 가중치 $\alpha(X_t; \omega)$를 출력.
    *   **Inner Objective (베이스 학습):** 동적으로 생성된 $\alpha$를 사용하여 $\theta$ 학습
        $$ \theta^*(\omega) = \arg\min_{\theta} \sum_{(X,Y) \in \mathcal{D}_{train}} \left[ \alpha(X; \omega)\mathcal{L}_{SSIM}(f_\theta(X), Y) + (1-\alpha(X; \omega))\mathcal{L}_{MAE}(f_\theta(X), Y) \right] $$
    *   **Outer Objective (메타 학습):** 검증 세트에서의 순수한 평가 지표(예: MSE)를 최소화하도록 $\omega$ 학습
        $$ \omega^* = \arg\min_{\omega} \mathcal{L}_{val}(\mathcal{D}_{val}; \theta^*(\omega)) $$
*   **기대 효과:** 날씨 상황에 따라 "구조 유지(SSIM)"와 "값의 정확도(MAE)" 간의 트레이드오프를 최적으로 자동 조절하여 전반적인 성능을 향상시킵니다.

### 3. Meta-Reweighting for Hard Samples (Curriculum Learning)
**개념:** 논문의 `Fig. 3`에서 언급된 것처럼 제주도나 쓰시마 섬 같은 특정 지역이나 급변하는 날씨 패턴(Hard Samples)에서 에러가 높습니다. 일반적인 학습은 모든 샘플을 동일하게 취급합니다. 메타 러닝을 사용하여 **현재 모델이 어려워하는 샘플(Loss가 높은 구간)에 더 높은 가중치를 부여하도록 학습 가중치(Instance Weights)를 학습**합니다.

*   **수식 및 노테이션:**
    *   학습 데이터셋의 $i$번째 샘플: $(x_i, y_i)$
    *   샘플 가중치 네트워크(Meta-Weight Net): $V(L_i; \omega)$, 여기서 $L_i$는 해당 샘플의 손실값.
    *   **Inner Loop:** 가중치 $v_i = V(\mathcal{L}(f_\theta(x_i), y_i); \omega)$를 적용하여 베이스 모델 $\theta$ 업데이트
        $$ \theta_{t+1} = \theta_t - \eta \nabla_\theta \left( \frac{1}{B} \sum_{i=1}^{B} v_i \cdot \mathcal{L}(f_{\theta_t}(x_i), y_i) \right) $$
    *   **Outer Loop:** 업데이트된 $\theta_{t+1}$이 검증 데이터(Validation Set, Unbiased)에서 성능이 좋아지도록 $\omega$ 업데이트
        $$ \omega_{t+1} = \omega_t - \beta \nabla_\omega \mathcal{L}_{val}(\mathcal{D}_{val}; \theta_{t+1}(\omega)) $$
*   **기대 효과:** 데이터 불균형(맑은 날이 많고 흐린 날이 적음) 문제를 해결하고, 모델이 예측하기 어려운 복잡한 구름 패턴에 더 집중하게 만듭니다.

### 4. Hyperparameter Meta-Optimization (Adaptive Learning Rate)
**개념:** 논문에서는 Cosine Annealing 스케줄러를 사용했습니다. 단일 태스크 메타 러닝의 관점에서, **학습 과정 자체를 최적화**하기 위해 그레디언트의 상태에 따라 학습률(Learning Rate)을 동적으로 조정하는 메타 옵티마이저를 학습할 수 있습니다. 이는 "단일 태스크를 반복 학습하면서 수렴 속도와 최종 성능을 개선"하는 전형적인 방식입니다.

*   **수식 및 노테이션:**
    *   베이스 모델 파라미터: $\theta$
    *   메타 파라미터(학습률 제어 정책): $\omega$ (예: LSTM 기반의 메타 옵티마이저)
    *   현재 그레디언트: $\nabla_t = \nabla_\theta \mathcal{L}_{task}(\theta_t)$
    *   **Update Rule (Meta-Learner):** 기존의 고정된 $lr$ 대신, 메타 러닝 모델 $g_\omega$가 출력한 값으로 업데이트
        $$ \theta_{t+1} = \theta_t - g_\omega(\nabla_t, \dots; \omega) $$
    *   **Meta-Objective:** $T$ 스텝 동안 학습한 후의 누적 손실 최소화
        $$ \min_\omega \mathbb{E} \left[ \sum_{t=1}^T \mathcal{L}_{task}(\theta_t) \right] $$
*   **기대 효과:** Cosine Annealing과 같은 사전 정의된 스케줄보다 더 빠르게 수렴하고, 로컬 미니마(Local Minima)를 더 잘 탈출하여 최종 예측 정확도를 높입니다.

### 5. Spatiotemporal Context-Aware FiLM Generation (Adaptive Architecture)
**개념:** 논문의 핵심인 `FiLM` 레이어는 고정된 인코더(GLCM, Seasonality)를 통해 $\gamma, \beta$를 생성합니다. 이를 메타 러닝 관점으로 확장하여, **계절(Season)이나 시간대(Time of day)를 각각 다른 태스크(Task)로 간주**합니다. 메타 러닝을 통해 "계절별 특성(Task Context)"을 더 잘 반영하는 `Context Embedding`을 생성하도록 합니다. 즉, **FiLM 파라미터 생성기 자체를 메타 러너로 정의**합니다.

*   **수식 및 노테이션:**
    *   베이스 모델(U-Net) 파라미터: $\theta$
    *   컨텍스트 생성기(Meta-Network) 파라미터: $\phi$
    *   현재 태스크(특정 날짜/시간)의 컨텍스트 정보: $C_t$ (GLCM, Season vector 등)
    *   FiLM 파라미터 생성: $(\gamma_t, \beta_t) = h_\phi(C_t)$
    *   **Forward Pass (Modulation):** 베이스 모델의 특징 맵 $F$ 변환
        $$ \hat{F} = \gamma_t \odot F + \beta_t $$
    *   **Optimization (Bi-level):** $\phi$는 여러 계절(Task Distribution $p(\mathcal{T})$)에 걸쳐 빠르게 적응하거나 일반화되도록 학습.
        $$ \min_\phi \mathbb{E}_{\tau \sim p(\mathcal{T})} \left[ \mathcal{L}_{task}(\mathcal{D}_\tau; \theta, h_\phi(C_\tau)) \right] $$
*   **기대 효과:** 논문에서 언급된 계절별 성능 격차(봄에는 잘하지만 겨울에는 못하는 등)를 줄이고, 특정 계절의 데이터가 적더라도 메타 네트워크가 다른 계절에서 배운 지식을 전이(Transfer)하여 안정적인 성능을 냅니다.

</details>
