---
title: "Meta-Learning in Neural Networks: A Survey"
subtitle: "Section 2: Background (Definitions)"
author: "Hospedales et al."
format:
  revealjs:
    theme: simple
    slide-number: true
    transition: fade
    footer: "Meta-Learning Survey - Background"
---

## 2. Background

**핵심 주제**
Meta-Learning의 정의와 기존 머신러닝(Conventional ML) 및 하이퍼파라미터 최적화(HPO)와의 차이점.

---

## Defining Meta-Learning

> "Meta-learning is difficult to define, having been used in various inconsistent ways..."

*   **Learning to Learn**
    *   **과정(Process):** 여러 학습 에피소드(Episodes)에 걸쳐 학습 알고리즘을 개선하는 과정.
    *   **Conventional ML:** 여러 데이터 인스턴스(Instances)에 걸쳐 모델의 예측(Predictions)을 개선.

---

## The Meta-Learning Loop

두 가지 레벨의 알고리즘으로 구성됩니다.

1.  **Inner (Base) Algorithm**
    *   특정 태스크(예: 이미지 분류)를 풉니다.
    *   데이터셋과 목적 함수(Objective)로 정의됨.
2.  **Outer (Meta) Algorithm**
    *   Inner Algorithm을 업데이트합니다.
    *   **Outer Objective:** Inner Algorithm의 일반화 성능(Generalization)이나 학습 속도(Speed)를 개선하도록 최적화.

---

## Base Learning vs Meta-Learning

| 구분 | Conventional ML (Base) | Meta-Learning (Outer) |
| :--- | :--- | :--- |
| **Input** | Data Instances (Image, Label) | Learning Episodes (Task, Algorithm, Performance) |
| **Goal** | Improve Model Prediction | Improve Learning Algorithm |
| **Optimization** | Single Task | Distribution of Tasks |

---

## Distinction from HPO

*기존의 Hyperparameter Optimization(예: Grid Search)도 Meta-Learning인가?*

*   **넓은 의미:** 그렇습니다. (Learning to Learn의 정의에 부합)
*   **Contemporary Neural Meta-Learning:**
    *   단순 검색이 아님.
    *   **Explicitly Defined Meta-level Objective** (명시적인 메타 목적 함수).
    *   **End-to-End Optimization** (메타 목적 함수에 대해 Inner Algorithm을 End-to-End로 최적화).

---

## Summary

이 섹션에서는 "Learning to Learn"으로서의 메타러닝을 정의하고, 현대적인 신경망 기반 메타러닝이 기존 방식과 어떻게 차별화되는지(End-to-End Optimization)를 설명했습니다.
